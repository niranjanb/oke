%!TEX root = main.tex
\begin{center}\textbf{Project Summary}\\
Niranjan Balasubramanian (PI)
\end{center}
%\author{Niranjan Balasubramanian}
\eat{
Each proposal must contain a summary of the proposed project not more than one page in length. The Project Summary consists of an overview, a statement on the intellectual merit of the proposed activity, and a statement on the broader impacts of the proposed activity.
The overview includes a description of the activity that would result if the proposal were funded and a statement of objectives and methods to be employed. The statement on intellectual merit should describe the potential of the proposed activity to advance knowledge. The statement on broader impacts should describe the potential of the proposed activity to benefit society and contribute to the achievement of specific, desired societal outcomes.
The Project Summary should be written in the third person, informative to other persons working in the same or related fields, and, insofar as possible, understandable to a scientifically or technically literate lay reader. It should not be an abstract of the proposal.
}
\eat{Textual information sources are typically authored for human consumption and therefore assume a level of background knowledge and 
inference capacity that is beyond the reach of current information extraction systems. A basketball article might assume which Michael Jordan one is talking about, an article on a genome will assume what gene a RF32 refers and so on. Even news articles written eaves many other dots that a human reader would implicitly and effortlessly connect. This knowledge is extremely difficult to attain. This project aims to extract this background knowledge about events and entities of the world to help extraction and summarization systems produce riche yet concise representations of information in texts. }

\eat{Existing information extraction systems do not have access to this kind of knowledge. Open IE systems extract every (binary) relation mentioned in text with no notion of salience or structure. Template-based IE systems aim to extract information into a richer structure but depend on manually specified templates, which result their applicability to a small set of domains. Prior work on automatic generation lead to a scalable method for producing schemas. However, the quality of the resulting schemas were lacking. The schemas were largely incoherent schemas that often mixed distinct events and roles. The light-weight subject-verb or verb-object representation improved robustness of estimates but often missed essential context. Our own preliminary work in this area showed that it is possible to use a richer representation and address the resulting sparsity issues with some simple generalization techniques. }

	
\eat{The project will proceed in three phases. In the first phase of the project, we focus on the designing the representation and extracting information from large corpora using existing IE systems. We will design a rich representation for the targeted knowledge by leveraging existing ontologies for entities and relations (e.g., YAGO, NELL, Freeebase) where possible and using text derived representations in other places. Then, we will investigate techniques for aggregating and generalizing information in the specific instances. In particular, we will develop automatic methods for choosing the right level for mapping into a type hierarchy for the arguments and the relations. In the second phase, we will focus on graph-based approaches for generating open-domain schemas using the generalized extractions. In our preliminary work, we identified the graph properties that indicate specific characteristics for good schemas and developed a suitable method that exploited the graph properties to produce high-quality schemas. In the third phase, we will focus on applying the generated schemas to two end tasks: event extraction, and summarization. For event extraction we will build extractors. Schemas can be thought of as high-precision models of events, which can then be expanded to include higher-recall extractors via bootstrapping. For summarization, we will use schemas to help select sentences for the standard MUC single document summarization task. We will iterate and refine the schema representation and generation based on their performance in these end tasks. }

Information extraction systems are critical for mining useful information from the massive amounts of texts available on the web. Textual sources written for human consumption raise two types of challenges for extraction systems: (i) They include many non-relevant information (e.g., ``Bill gates, {\em the father of two}, founded Microsoft ..."), and (ii) They exclude some useful information, expecting the reader to have a level of background knowledge or inference capacity. For example, a basketball article might assume which {\em Michael Jordan} one is talking about, an article on a genome will assume what gene a {\em RF32} refers to and so on. Existing information extraction systems do not have access to this kind of open-domain knowledge. Open IE systems extract every (binary) relation mentioned in text with no notion of salience or structure. Template-based IE systems aim to extract information into a richer structure but depend on manually specified templates, which result their applicability to a small set of domains.

The main goal of this project is to investigate scalable methods for producing high-quality open-domain knowledge about events and their effective application to event extraction and summarization. Building on our preliminary work on event schemas, we will target effective representations with adequate generalization, and scalable graph-based methods for identifying schema elements. We will leverage existing Open IE extractors, as well as knowledge-bases such as Freebase, YAGO, and NELL to produce a rich and effective representation. These schemas will specify the typical participants in an event, their roles, and the dependencies between various sub-events. To keep our investigation grounded, we will iterate on the design and development focusing on two end tasks {\em event extraction} and {\em summarization}. %First, we will transform the schemas into effective extractors by developing methods for expanding the schemas to include extraction patterns.  Second, we will improve state-of-the-art summarization systems by injecting a model of salience for entities, sub-events and their dependence derived from schemas. , 

{\bf Intellectual Merit} Through the course of this project, we will have made significant contributions in generating knowledge about open-domain events. Our first contribution will be in representing events using a combination of information from multiple sources and effective mechanisms for generalizing from specific event mentions. A second fundamental contribution would be the exploration of probabilistic graphical formalisms for identifying clusters of relations that correspond to an event. This involves contributions in methodology for constructing large relation graphs, encoding relevant phenomena via graphical properties, and algorithmic adaptations to score the desired clusterings. The third major contribution of this work would be novel techniques for expanding relation extractors from a high-precision seed set. \eat{Unlike prior approaches for event template construction where schema specific documents were gathered first, we will focus on an approach that will construct schemas first and then identify schema specific documents later to expand.}The fourth major contribution here would be methods for estimating models of salience and dependence between schema elements and empirical evaluations of the utility of the information in event schemas for {\em event extraction} and {\em summarization}.

%understanding of the representation needs for event schemas in relation to event extraction and summarization and demonstration of the value of schema like knowledge for these tasks. The method and techniques can scale to and spur research on similar problems in other domains (e.g., extracting processes from textbooks, identifying schemas in research studies). 


{\bf Broader Impact} 

Extracting and summarizing information is a central to knowledge acquisition and organization, which has direct societal benefits and impacts many different communities including business intelligence, scientific research community, as well as the Artificial Intelligence community. All these diverse communities can benefit from scalable information extraction and summarization systems. Event schemas are an important step towards automatically building script-like knowledge from text, which can benefit knowledge-intensive applications such as reasoning and Question Answering, which further the cause of Artificial Intelligence. 

{\bf Keywords} Knowledge extraction, Information extraction, Event extraction, Summarization

%\end{document}
